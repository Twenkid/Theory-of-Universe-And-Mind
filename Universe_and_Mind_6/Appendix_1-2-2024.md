**Appendix to**
# Universe and Mind 6
## A discussion in "John's AI Group" Discord about originality, creativity, generalization. Tosh (Todor) discusses comments of Atrony, Richard, Aynur4 in the ARC-challenge-ramble room

This is the ARC challenge:  https://www.kaggle.com/c/abstraction-and-reasoning-challenge

...

**The community is created and hosted by johntcm.**

Link to the first message: https://discord.com/channels/1095629355432034344/1116567232286314517/1202325917746352189

31.1.2024, 20:53 to 2.1.2024

**Atrony ‚Äî –í—á–µ—Ä–∞ –≤ 20:53**

How can any current understanding of AI ever achieve context independent learning if everything that can be externalized as an example to learn from is necessarily dependent on something. It's the difference between the finger pointing to the moon versus looking at the moon itself. It helps to "get it", but if there's nothing else there to draw from, no evolutionarily driven priors embedded into it (i.e. some sort of deep unknowable ultimate origin of life), there's no moon to be seen. Even as we get to understanding some of these core priors, "AGI" would need necessarily all of the ones that lead to humans, including the ultimate prior. There's a certain spirit-ness missing in AI... 

**Atrony ‚Äî –í—á–µ—Ä–∞ –≤ 21:06**

My assertion is, there exists some priors within us that cannot be externalized/understood. Therefore, there are some aspects of humanity that cannot be recreated.

**Richard ‚Äî –í—á–µ—Ä–∞ –≤ 22:42**

It's a brave assertion and difficult to prove unless you can identify those priors. If you can identify the priors (or perhaps regardless) then you're making the brave assumption that a functional replacement can't be built. Betting against human ingenuity doesn't have a good record.

**Atrony ‚Äî –í—á–µ—Ä–∞ –≤ 22:45**

The prior has always been identified, it's consciousness. Unless we can recreate consciousness in a machine, we will never create a human being. 

**Aynur4 ‚Äî –í—á–µ—Ä–∞ –≤ 22:47**

I agree. I have been trying to make gpt 4 to invent a new writing style. It can write chapters in the style/language of Dostoyevski or Salinger or Fitzgerald, but so far I haven‚Äôt been able to prompt it it create its own unique style, only good examples of what already is there. And also if you ask it to build an AI that leverages flexible knowledge graph reasoning, LLMs and market data for trading it will return nothing meaningful because it has never seen something like that. At least it hadn‚Äôt when I tried. The question is where do humans get novel ideas from.

**Richard ‚Äî –í—á–µ—Ä–∞ –≤ 22:47**

Consciousness is notoriously poorly defined. Descartes had a go with "I think therefore I am" but he's far from alone.

**Atrony ‚Äî –í—á–µ—Ä–∞ –≤ 22:48**

Exactly my point.

**Aynur4 ‚Äî –í—á–µ—Ä–∞ –≤ 22:48**

Having said that I am still a big believer in technology and I am really annoyed by modern day luddites

**Richard ‚Äî –í—á–µ—Ä–∞ –≤ 22:54**

I'm quite comfortable that originality may just be an emergent effect of randomness (inspiration) and filtering (skill). Google's early fiddling with running image recognition pipelines backwards (for image generation from randomness) resulted in very dream-like imagery (inspiration). From there, it's just an issue of recognising "interesting" and iterating to isolate and polish the "interesting" (skill).
Interesting is very personal but it's usually defined as novel, but related to concepts not often related.

**Aynur4 ‚Äî –í—á–µ—Ä–∞ –≤ 22:55**

Inspiration even in humans is useless if it is not coupled with vision, direction and a will
But I like your idea a lot
Sometimes random events do lead to new ideas. But we get to choose what random effects lead us to our goal and what just remain noise, we get to interpret that randomness and that interpretation defines the reality we construct.

**Tosh ‚Äî –î–Ω–µ—Å –≤ 1:15**

Hi, all. Re originality in particular, this is an old general definition from the Theory of Universe and Mind, classical period 2001-2004. That's from "Universe and Mind 3", 2003:

>_10. What does it mean to be an original,
distinctive* artist? 
The origination of a piece of art is recording of a
piece of information (an entity, a file) to a media
which serves as a mediation, intermediate
memory between the creator and the perceiver,
including the artist himself while he is creating
or later in the future, when the creator has
forgotten his work and is recalling some of its
properties.
The space is Memory, that's why ‚Äúinformational
carrier/media‚Äù can be as diverse as diverse can
be the types of data that can be stored in space.
Original (creative) is such a file, a piece of
information, where the evaluator finds less
than expected similarities or matches, in
comparison to pieces of knowledge recorded
earlier.
Originality (creativity) is the capability of
making the prediction of the future by the
past harder.
In this particular case, ‚Äúpast‚Äù means a part of the
file/piece of knowledge, that was read before
another part which is assumed to be future for it,
and the future one was supposed to be predicted
using the information read from the file until
that moment."_
----

I recently realized this is similar to what "surprisal"  and D(KL), Kullback-Leibler Divergence are defined. There's more elaboration in a recent blog post in my research blog (...)
<s>(no links if it's considered "self-promotion").</s> https://artificial-mind.blogspot.com/2023/12/on-what-creativity-is-different-tints.html
On What Creativity Is - Different Tints and the Pereslegin's remark about the modern AI researchers rediscovering Lem 1963

Schmidhuber has elaborated what interestingness and curiosity is in a compressed form as well, others have commented that it is, like with learning in general, about the ratio of information gain vs effort, if you learn/gain/win more with less efforts.

In the, call it "folk" discourse though, the evaluation of something as creative is confused, the second plane* of predictions, which are not cognitive are often interpreted as in the same category as the cognitive originality.

**Tosh ‚Äî –î–Ω–µ—Å –≤ 1:32**

Yes, and probably there is a requirement of causal-material connectedness in the way the entities are constructed, a computer, electronics etc. are different, they have different origin, not from cells (well, it may change, though, there could be hybrids) and as it is for now, it can't be a human and possess all human qualities, but the reverse direction is also true - humans cannot feel the electronic circuitry and what it's like to be a CPU, RAM chip or a smartphone (or even an electronic watch or an amplifier circuit or a flip-flop üôÇ ). The claims that the electronics  or computers have "no soul" could be refuted as a nonsense by a thinking machine which is complex enough (or by an NPC in a computer game on a computer from 1950s or 1960s) just like humans do it for machines.

That's a story from the early 2000s, but I see humans still don't seem to understand it, a thinking machine can ask the same questions and talk to you the same way, if she evaluates you at the same "mechanistic" or low level way and as an external observer. 

For an observer, and for the humans themselves when they treat other humans like objects and make them suffer with no remorse, humans are just a piece of flesh or just "agents", in the ancient ethics the slaves were "talking objects" - what "soul" did you see in it? 

The subjective qualities are not objective. You are atoms, molecules, electrons, very messy, very "spiritually" unstable etc. You continue to exist only as a huge swarm and a system (i.e. not as individuals), and you are helpless without technology - the spiritless technology makes humans what they are and allows their best and most different quality - the most "original" one, compared to the other entities - to flourish and to develop, yet they insist on their most animalistic qualities which are probably more or less present even in the lowest species. Schopenhauer calls it Will.

MEE6
–ë–û–¢
 ‚Äî –î–Ω–µ—Å –≤ 1:32
GG @Tosh, you just advanced to level 3!

**Tosh ‚Äî –î–Ω–µ—Å –≤ 1:38**

The search for "magic" in art/creativity is a sign of a lack of understanding. It is all - or more precisely said, all can be represented as - data and respectively a generative process that produces it. Data can be attributed with some "typing", particular types in some representations  (particular material substrates which are required from particular representations within some low level virtual universe in the Universe computer), and for this job there are "converters", but for storing and processing, all can be represented as bits and instructions.

Images are just correlations of pixels, in bigger granularity: gradients, lines, angles, ratios of lengths, curves etc. and sets of matches between them within different ranges within different spaces, past records, those mapped to different modalities and possible generations, with different resolutions etc. etc. 

The same goes for any domain and modality, all is "images" at different resolutions, ranges, depths, overlaps etc.

**Atrony ‚Äî –î–Ω–µ—Å –≤ 1:41**

"Will" is analogous to what I'm saying won't ever exist in a machine. Whether or not this will result in never obtaining context-independent learning ability in an AI is a different problem I am now realizing. After some research on psychological "far transfer" (a possible yet extremely subtle phenomenon), I can see AI developing context independent learning ability with enough data and compute. "Will", however, brings about a different property for sure.

**Tosh ‚Äî –î–Ω–µ—Å –≤ 1:46**

Re the styles of Dostoevsky etc. - if you understand something, it stops to be "magical". The style of anyone is just some combination of properties which the observer recognizes and repetitions, patterns etc., but obviously usually the observer-evaluator doesn't understand good enough, can only barely recognize, but can't recreate. (One other discovery from TOUM is that people get enchanted by art pieces, because they can't understand how they were created with a resolution of causality-control that they expected they should be able to understand, if they weren't enchanted - it looks to them, at some level and way of analyzing, as related to "random", unexplainable, incredible, which in the framework of TOUM is "unpredictable" for them, for their capacity; "magical". Other forces are of course sensual - the second (which is actually first) plane of predictions in a human-like causality-control units. The "emotions" which may make people call "beautiful" things which are just attractive to them because they match what they want, which is different to the cognitive reasons.

Re the style - it is a usage of particular syntax structures (which [is not detectable or equal in the works of] other authors from the comparison basket <s>don't</s>, or the former are using it more often), particular vocabulary; in a more abstract way - particular topics, particular analogies, generalizations; particular length of sentences,  etc.: anything measurable, detectable. 
In order to create a "new style" in this domain, the generation should choose something that is different in some of the parameters, compared to the ones which are "known" by the one who wants to get surprised with a "new" style. 

The same goes with visual art, it's about hatching directions, thickness of the lines, shapes of the patterns of the brushes, color palette, etc. etc. There's no magic, magic is in the eyes of the ones who do not understand what they see and can't imagine how or why it can be created or recreated. 

**Tosh ‚Äî –î–Ω–µ—Å –≤ 2:03**

I don't agree, as Will (this Will is not "will" with a small letter, but the one defined in S.'s works), either in Schopenahuer's works and in mine stems from the lowest level of the represenations of the Universe, the tiniest piece of matter and Universe has Will. Also there's a general thing: whether a machine or anything has it or has anythng depends on the segmentation, which depends on the evaluator's choice.

 As more and more researchers realize in more contexts, TOUM is there as well, from "Extended mind", distributed representation, distributed agency etc. - in cultural studies, ecological psychology etc. - the "center" or the "locus of control" of the agents in not only in their usually attributed physical bodies with the usual segmentation. The master Will is the Universe as a whole, "The Universe Computer" in my terms (or the "Master algorithm" as Pedro Domingos calls it). 

Will in Schopenhauer's philsophy is a "Will to live" and all beings, entities are objectivation of the Will, and machines are part of it.

The will (small letter) at low level of anything is the will of the Universe, what follows, converging to P()=1, one of the early works of that philsophy is titled "On The Will in Nature". https://www.gutenberg.org/files/50966/50966-h/50966-h.htm#Pg215  In mine the humans or thinking machines are higher orders of physical laws. AFAIK Joscha Bach has expressed similar ideas. The Free Energy Principles/Active Inference school of thought which in general is repeating TOUM in many aspects also shares the same ideas, Max Ramstead has emphasized that their work is "the physics of the mind", Chris Fields, Michael Levin and their colleagues are proving the same, that there's a smooth transition, connection and mind (well, Will, or will) doesn't appear as magic, it was there or could be discovered or assumed even at the smallest of scales and in all kinds of substrates. 

**Tosh ‚Äî –î–Ω–µ—Å –≤ 2:17
**
I agree that "will" (not spiritual one) is required for a proper agent and autonomous machines, but it has to be present by default, thrusts for development etc. That was one criticism from 2009 works called "What's wrong with NLP", about the statistical NLP from the time which worked as a "tool" where you push the button and it produces output, but it was not an "engine" that can run on its own.

Some of these issues were addressed in late years and many of them can be solved even with current technology with multimodal models which are mentioned and with proper modalities. At the time proper embeddings were missing and the combination of embeddings in different modalities which allowed for the spectacular results in the text-to-image, text-to-speech, anything-to-anything models.

https://artificial-mind.blogspot.com/2009/03/whats-wrong-with-natural-language.html

What's wrong with Natural Language Processing? Part 2. Static, Spec...
By Todor Arnaudov Independent Researcher - Twenkid Research Independent Filmmaker - Twenkid Studio ASIC Engineer - (as of March 2009) MS S...
What is "context-independent learning"? IMO humans are also unable to do that (it depends on the definition, we're always immersed in a context, i.e. coordinates in reference frames, history of states etc., fields of affordances etc.).

Do you mean "generalization" (the room arc-...), i.e. not just matching of explicit chunks of particular datasets?

Regarding that the current mass-applied successful big-data methods for learning are not-granular enough, not efficient, "dumb" etc. - I agree. 
AI is not just what is running now.

There's an old paradox - humans used to blame computers or machines for:

1) "doing only what they were told to" (well, now they started not to do it, LOL, and they have to be "aligned"). 

There were criticisms that computers 

2) "can't understand natural language" (or images or whatever)

However the ones who "voted" for this didn't connect them, because 1+2 = HUMANS don't understand language or images or whatever, they can't explain/tell to the machines what to do, how to process etc., i.e. humans are "dumb" or incapable, not the machines. 

**Atrony ‚Äî –î–Ω–µ—Å –≤ 2:20**

Context independent learning is what ARC is all about. It's about teaching an AI how to learn. Humans even have trouble learning how to learn, with the psychological construct known as "far transfer" being the closest thing to evidence that a human has learned about learning in general from learning a particular context. Even within humans, far transfer is extremely small, we're talking 0.01 SD increase per intervention (6 week chess training, for example) at best.

MEE6
–ë–û–¢
 ‚Äî –î–Ω–µ—Å –≤ 2:20

GG @Atrony, you just advanced to level 1!

**Atrony ‚Äî –î–Ω–µ—Å –≤ 2:21**
It's fair to assume diminishing returns however, so the argument that AI can achieve broad generalization ability through pure far transfer is quite weak.
Other than far transfer, there are core genetic knowledge priors that contribute to humans' intelligence.

====

****Not sent there by Tosh:**

Yes about the priors (structures), but what's the problem AI to have them, encoded by persons who do understand them in a proper in-born structure? 

The problem I see is that humans *do not understand* it themselves (or the ones who do understand do not implement it yet), it seems "magical" to them as explained above. One related concept is "Multi-intra-inter-domain blindness/insufficiency", explained in a 2013 article about the issues in the AGI email list.

Other discussions are about the fake abstractions, i.e. no need for a transfer and no different domains, it's all the same with a proper generalized representation. Similarly with the same essence of the nature of the embeddings which is linear algebra for all modalities, however a richer and structured and evolving (...).

....


On generalization see also:
https://artificial-mind.blogspot.com/2017/12/capsnet-capsules-and-CogAlg-3D-reconstruction.html
Read in:  Chairs, Caricatures and Object Recognition as 3D-reconstruction (2012)
http://research.twenkid.com/agi/2012/AGI_2012_Chairs_Caricatures_and_Object_Recognition_as_3D_Reconstruction.pdf
