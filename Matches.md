# Matches betwen Theory of Universe and Mind - definitions, reasoning and predictions -and other later theories and works
## Essential principles, insights, reasoning from TOUM and comparison to analogical concepts from other theories, strategies and what actually happened and happens in the reality

__A work in progress, just a beginning: see also the main readme and other articles__

## Dr. MAXWELL RAMSTEAD - The Physics of Survival @ "Machine Learning Street Talk"
### https://youtu.be/8qb28P7ksyE  @ 16.7.2023


**8.8.2023: Todor:** A good talk and yet another proof that FEP (Free Energy Principle) is another wording of some of the core discoveries of the Theory of Universe and Mind by Todor Arnaudov, then a teenager, originally 2001-2004, first publications in Bulgarian in the e-zine "The Sacred Computer".
It was taught during the world's first University courses in Artificial General Intelligence, offered by the same author in 2010 and 2011 at Plovdiv University, Bulgaria, and presented live for general audience twice in 2009, followed by an interview in a then maybe the best and most popular Bulgarian popular science magazine "Obekty". In 2003 some of the ideas, about the general principles for all kinds of modalities, were also presented for general audience in a strategic essay on a competition "How will I invest 1 million with the biggest benefit for my country". See more details below and in the references, and the concrete matches from this specific talk.

### Concrete matches from the content of that very video on the Free Energy Principle

* For example the concept in TOUM which seems analogical to FEP's Markov blanket is the Causality-Control Unit (Управляващи устройства, подвселени, въображаеми вселени, подмашини и др.) - also virtual universe, machine, subuniverse, universes at different levels. 

* The ambiguity of the boundary of the Markov blankets in FEP maps to two foundational concepts from TOUM: resolution of perception and resolution of causality-control and one postulate, that the only "real" causality-control (actual, and not "virtual" in that narrow sense) is the one where the control unit predicts (causes, controls) the target controlled unit with the resolutions of perception and control which are equal to the highest possible ones at the universe where the target CCU exists and operates. I.e. if it fully causes and generates it. Usually that is impossible, except for the Universe as a whole: the global "generative model". Humans, human's "consciousness" for example controls (predicts) a ridiculously tiny bandwidth regarding intentional causation, i.e. muscular motions. 

* As of the boundaries - everything, the selection process, which belongs to what, is decided upon selected resolutions from both modalities and other parameters, it's a filter which depends on the observer-evaluator. This is the same like feature selection. 
* The law that the mentioned "dynamo" mathematician has discovered, regarding bigger Markov blankets being more predictable -- was one of the foundational generalizations from the early TOUM. The biggest "Markov blanket" (Casuality-control unit, Virtual Universe) is the whole Universe and it supposedly predicts and "knows" the future with the highest possible certainty: P=1, however it happens at the highest possible resolution only, at the machine language of the Universe at the lowest level (in the view to the Universe as a Computer, as that's one other name of TOUM: The Universe Computer). The subuniverses' predict at lower resolution and/or lower range, however they can predict many steps ahead (counted at the lowest time clock). The evolution (the development) of the Universe is directed towards the creation, agglomeration, expansion, extension of ever bigger causality-control units which resemble the whole/the Universe, their function is to predict the future with ever higher precision, scope, range etc., the final aim is P=1, as the whole Universe, this is their limit as in Calculus. Computers are examples of such virtual universes and human mind also converges at mathematics and computer-like operation at its highest conscious levels.

* Connected to the above is one of the basic, foundational insights and logic in one of the early works, that the laws of the random numbers actually suggest determinism, or more "objectively technically defined": a global "observer", in my terms it would be also an "evaluator"(observer-evaluator) - the Universe as a whole "has" to watch all events and balance them so the random numbers distribution are always aligned with the target value (with some precision). That happens because the events are connected, they are generated by some common generative algorithm and they interact, they are not independent. Note that "events" could be very abstract or linked between many levels of the hierarchy of causality-control units ladder (it is not always strictly hierarchical, it is heterarchical and the structure of which we talk depends on the observer-evaluator choice of representation, the "Markov blankets", the causality-control units): quarks-protons/neutrons, electrons, atoms, parts of molecules/molecules, macromolecules, cell organelles, systems of them, cell, tissues, organs, systems of organs, organisms, groups of organisms (and some abstract "parts" of these systems which can't be physically cut, but they could be theoretically induced by modeling the interactions and behaviors...) etc. 

* TOUM s not finished, "Universe and Mind 6" is coming and there are a lot of unpublished work which goes with more "specific generalisations" about cognition, linked with languages of thought, one notation called "Zrim". 

* The example of Max about the engines is exactly as one of my first comments in 2018 when I first heard of FEP (from Friston's Wired interview and from a short article in Wikipedia): that was mine comment regarding a paper called "Ultimate AI" by a follower of K.Friston:
https://artificial-mind.blogspot.com/2018/12/ultimate-ai-free-energy-principle-and.html  (7 December 2018)
>(...)
>2. CogAlg and Free Energy Principle
>I asked the owner of the CogAlg project Boris about his opinion, he said that he's been hearing about that theory "at least from a decade" and in short he didn't seem impressed, because it was "nothing novel".

>As of myself, I think the explicit emphasis of the idea of reducing the space of states for the living organisms and intelligence is suggestive for people who face these ideas for the first time, however it's somewhat obvious for hierarchical systems and even simple "machines", as the gears, the pistons etc. serve as "sub-spaces" which limit and guide the space of possible states.

>As defined in the most ancient basics of "my theory", the higher level patterns are constructed by selected sequences/sets of elements from the lower level which serve as "instructions" (discrete), therefore not all possible combinations are covered. Only a limited space is legal, which respectively reduces the search/combinatorial space of possibilities at the higher level, therefore it has "a reduced space". That's seen in the hierarchical structures in nature: atoms, molecules, cells, tissues etc.

>That "free energy principle" is yet another proof that the general direction towards AGI are getting established in different domains by different researchers.

Etc. (I'd like to comment on "every line" and all matches, but I didn't have an opportunity when I first listened to the record and these comments are by memory).

----
(...)

## Continuation of the Intro ... 

Before the 2010 AGI course the TOUM was presented also in front of a general audience as early as 2009, once briefly mentioned  regarding the building block of intelligence - for Jeff Hawkins that was the cortical column, and for me in my theory: **"Universal simulators of virtual universes"** during a 3-minute presentation, titled "My story in AI", performed on the stage of theater "Sofia" during the <a href="https://www.youtube.com/watch?v=YgmsH21k3lI">Famelab final event</a> in May 2009. 
The second time was a long lecture at the Technical University of Sofia in September 2009, with a promotional title <a jref="https://artificial-mind.blogspot.com/2009/09/event-with-me-in-sofia.html">"The Time Machine Exists: The Mind"</a>:, and the slides' title was: 
**Principles of General Intelligence:<br> Intelligence ~ Universe** (the precise word in Bulgarian was Разум (Razum), it means all: (General) Intelligence, Mind, Consciousness: 
https://research.twenkid.com/agi/2010/en/General_Intelligence_Principles_Caffe_Sci_2009_MTR.pdf

![image](https://github.com/Twenkid/Theory-of-Universe-and-Mind/assets/23367640/9e416de0-cdf9-4756-a2e6-99d89ee753d4)

A brief summary about the lecture from 23.9.2009:
https://artificial-mind.blogspot.com/2009/09/event-with-me-in-sofia.html

### How the Razum works? Hierarchical self-organizing predictor of the future - a scientific performance | AGI event of mine in Sofia

I will have a scientific performance where I will explain the architecture and the principles of operation of the Razum (Mind, General Intelligence), their organic connection with the architecture and the way of working of the Universe and the brain, 
and how on that basis me and other researchers plan to create thinking machines.

(В научна шоу-програма ще обясня архитектурата и принципите на работа на разума, органичната им връзка с архитектурата и начина на работа на Вселената и мозъка, 
и как на тази основа аз и други учени смятаме да създадем мислещи машини.)

After that lecture I gave an interview for the magazine called "Obekty" titled:
<a href="http://artificial-mind.blogspot.com/2010/01/i-will-create-thinking-machine-that.html">"I will Create a Thinking Machine that will Self-Improve (an Interview with Todor): Dreamers and adventurers make the great discoveries. The scepticists' job is to deny their visions, and eventually not to believe their eyes"</a>
where I also defined these principles as the way AGI will be created and I made a prediction that there will be significant breakthroughs to basic AGI/general models in less than 10 years.

Todor Arnaudov, 2009:
"<b>- If you believe that it's possible for us to build an AGI, why we didn't manage to do it yet? What are the obstacles?</b>

I believe that the biggest obstacle today is time. There are different forecasts, 10-20 years to enhance and specify current theoretical models before they actually run, or before computers get fast and powerful enough. I am an optimist that we can go there in less than 10 years, at least to basic models, and I'm sure that once we understand how to make it, the available computing power would be enough. One of the big obstacles in the past maybe was the research direction – top-down instead of bottom-up, but this was inevitable due to the limited computing power. For example, Natural Language Processing is about language modeling; language is a reduced end result of so many different and complex cognitive processes. NLP is starting from the reduced end result, and is aiming to get back to the cognitive processes. However, the text, the output of language, does not contain all the information that the thought that created the text contains.

On the other hand, many Strong AI researchers now are sharing the position that a “Seed AI” should be designed, that is a system that processes the most basic sensory inputs – vision, audition etc. Seed AI is supposed to build and rebuild ever more complex internal representations, models of the world (actually, models of its perceptions, feelings and its own desires and needs). Eventually, these models should evolve to models of its own language, or models of human's natural language. Another shared principle is that intelligence is the ability to predict future perceptions, based on the experience (you have probably heard of Bayesian Inference and Hidden Markov Models), and that intelligence development is improvement of the scope and precision of its predictions.

Also, in order the effect of evolution and self-improvement to be created, and to avoid intractable combinatorial explosion, the predictions should be hierarchical. The predictions in an upper level are based on sequences of predictions (models) from the lower level. Similar structure is seen in living organisms – atoms, molecules, cellular organelles, cells, tissues, organs, systems, organism. The evolution and intelligence are testing which elements are working (predicting) correctly. Elements that appeared to work/to predict are fixed, they are kept in the genotype/memory, and are then used as building blocks of more complex models at a higher level of the hierarchy.

(...)
======================

Note that there is no explicit border and division between the physical particles and the living organisms.

* In 2003 in a strategic essay for a competition called:
### <b>"How would I invest a million with the greatest benefit for the development of the country?" </b>
June 2003
Original: https://www.oocities.org/todprog/ese/proekt.htm 
Machine translated, Google translate, 10.8.2023

In my opinion, a powerful future source of revenue, for which 1 million euros is an excellent start, because the key to making it happen is in the human brain, is the Thinking Machine (MM).

A machine equal to or surpassing human intelligence would become an unprecedented engine of scientific research and culture in the country that first managed to create it.
     
An expressive example of the potential of MM is the huge information flow through its memory, which can be managed down to binary. Man is capable, for a second, of outputting conscious information that is described by several tens of bits. This applies to speaking, singing, typing, moving the mouse pointer, drawing, playing a musical instrument. In the same second, an ordinary personal computer transfers, through its central processing unit alone, a billion times the information over which the machine has complete control. If such a powerful "stream of information" is controlled by reason, the "calculating hardware" will turn into an amazingly perceptive student, who would quickly become a prolific artist in all arts and a tireless scholar. Connected to robotic bodies, in the design of which, in fact, she could also participate, MM will be able to perform physical activities, to give a "friendly arm" to man and industry in the literal sense.

Since the MM's personality would be recorded as pure information - on computer media that could be overwritten and stored theoretically forever, unlike the human carrier of the personality - the brain, a machine trained to some degree could be reproduced simply by switching on a copy of her personality in a new "body" where she can begin to develop independently and learn only what is necessary for the new activity. All the sensible experience possessed by any previous MM will be readily transferable to another who will have the personality of her "mother" at birth.
        
Thanks to MM's mind being able to have a direct high-speed connection to a computing machine - processors from MM's own body, or another machine to which MM is electronically connected as a user - computer design, modeling and, generally speaking, creativity, handed to the Machine, will be done much faster than
man does. All input and output devices will be part of the "imagination" of the MM, therefore much faster than the currently mandatory moving, equivalent to inert and slow human input devices.

The machine will be able to be a programmer, of course. If given the opportunity to explore her device in detail, once created, she could assist in improving it to the limits provided by the particular "hardware" on which her computer "soul" universe resides. MM can go even further - the "soul" could refine the "body" - the "electronic flesh", until physical limits are reached. In this
role, the Machine will work as an electronic engineer looking for new circuit solutions; a physicist perfecting current technologies for the manufacture of integrated circuits and nanotechnology, or a discoverer of as-yet-unknown ways of building machines."

(...)

I believe that it is only a matter of years until we find the right "parts" and build a "machine" from them to overcome the "Wall" and meet the Machine.

**STRATEGY**

According to my strategy, a scientific-research Institute would be founded, which would unite computer scientists, engineers, art critics, linguists, philosophers, psychologists, neuroscientists; multilingual translators; creators in various arts - writers and poets, composers and musicians; artists, photographers and film directors. The members of the Institute will be, with advantage, having knowledge and skills in several fields, both scientists and creators, because the goal of the searches will be to discover the commonality between all manifestations of reason, between the sciences and the arts. The form of thought is different in different manifestations of thinking, but its essence, the underlying mechanisms, are the same, and only the data with which it works - word, sound, images, sequences of images, abstract concepts and etc.
The institute will also play the role of a "wing" that finds, "protects and wings" gifted people to support their development and, if they wish, to enjoy their talent in research.

The Institute will have a program house, in which "incidentally" will be produced "smart" application software using the developments of the Institute on the way to IR: programs for automated design, multimedia, word processing, translators, games, etc. application programs.
The goal of the Institute will be the programmatic creation of a MM [Thinking Machine], possessing universal capabilities for exchanging information with other computing machines, in particular robotic modules. The robots created by the robotics department will be, in addition to a way to use IR for physical activities, a means of attracting public attention and advertising for the Institute.

Once a Thinking Machine is realized, it will be able to be used in all creative spheres of human activity and in the work of the Institute itself.
I suppose that after the Discovery and the creation of the MM, running on standard computers, the Institute will be "armed" and will be able to set aside a design department to develop new complete computing systems specially adapted for the operation of the Machine.

(...)
